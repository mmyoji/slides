## Python Machine Learning 3rd

2018-01-25 @mmyoji

---

## Content

第4章 データ前処理

* 4.1 欠測データへの対処
* 4.2 カテゴリデータの処理
* 4.3 データセットの分割
* 4.4 特徴量の尺度を揃える

---

### 4.1 欠測データへの対処

* **欠測値** missing value : データ収集過程で誤りがあったり、 NaN や null になってしまっている値
* 対応
    * 欠測値がある列ないしは行を取り除く -> データが少なくなる
    * 欠測値を補完する。列の平均値など
* 他には最瀕値, 中央値などで置換する方法も
    * [欠損値の扱い - 機械学習によるデータ分析まわりのお話](https://www.slideshare.net/canard0328/ss-44288984/13)

---

### 4.2 カテゴリデータの処理

* カテゴリデータ ... 数値データではない値
    * 名義特徴量 nominal ... 大小関係がない
    * 順序特徴量 ordinal ... 大小関係がある
* こういった数値ではない情報をそのまま学習アルゴリズムには適用できない
* 数値データに変換してあげる必要がある
* **one-hot encoding** で変換する

---

#### one-hot encoding の例

color という特徴量があり、 blue/red/green の3種類の値を取るとする

| color_blue | color_red | color_green |
|:---:|:---:|:---:|
| 1 | 0 | 0 |
| 0 | 1 | 0 |
| 0 | 0 | 1 |

一つ目のサンプルは blue

---

### 4.3 データセットの分割

* `sklearn.model_selection.train_test_split`
* トレードオフを意識する
    * トレーニングデータが多い ... 学習に有益な情報が増える（かも）
    * テストデータが多い ... 汎化誤差の推定の正確性が上がる
* 最もよく使われる比率 training : test
    * 6:4. 7:3, 8:2
    * データセットが大きければ 9:1 が一般的

---

### 4.4 特徴量の尺度を揃える

* ほとんどのアルゴリズムではスケーリングをした方が性能が出る
* 決定木、ランダムフォレストでは不要
* スケーリングの手法
    * **正規化** normalization ... `[0, 1]` の範囲に変換
    * **標準化** standarization ... 標準正規分布(平均値0, 標準偏差1になるよう)に変換
* 標準化をすると外れ値の情報を維持できる

---

おわり

