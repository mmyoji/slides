# Introduction to ML with Python Ch2

---

## 教師あり学習

* ~p.45

---

## 目次

* 教師あり学習の特徴
* 2.1 クラス分類と回帰(教師あり学習問題の種類)
* 2.2 汎化、過剰適合、適合不足
* 2.3 教師あり機械学習アルゴリズム
  * 1. k-最近傍法

---

## 教師あり学習の特徴

* 入出力のペアである **訓練データ** が一定量必要
* 上記を使って、モデルを構築する

---

## 2.1 クラス分類と回帰

* 教師あり学習問題の種類
  * クラス分類 binary classification
  * 回帰

---

## 2.1 クラス分類

Classification

1. 2クラス分類 binary classification
  * e.g.) メールのスパム判定
2. 多クラス分類 multiclass classification
  * e.g.) アイリスの花の分類, web サイトのテキストから言語を判定する

---

## 2.1 回帰

Regression

* 浮動小数点数の予測
* 出力になんらかの **連続性** があれば回帰を使う
* e.g.)
  * 年収(の量 amount)を学歴, 年齢, 住所から推定する
  * とうもろこしの収穫量を前年の収穫量、天候、従業員数から予測

---

## 2.2 用語

汎化、過剰適合、適合不足

* 単純なモデルの方が、新しいデータに対してよく汎化できる
  * **過剰適合**: 過度に複雑なモデルを作ってしまうこと
  * **適合不足**: 単純すぎるモデルを作ってしまうこと
  * 複雑さを上げると個々のデータに対しての精度は上がるが、汎用的ではなくなる
     * 精度と汎用性の tradeoff
* モデルをいじりまわすより、データを増やした方がいいケースも多い

---

## 2.3 アルゴリズム

1. k-最近傍法
2. 線形モデル
3. ナイーブベイズクラス分類器

など

---

## 2.3 k-最近傍法 k-NN

KNeighbors分類機

* データを格納するだけでモデルを構築できる
* 訓練データセットの中から最も近い点（最近傍点）を見つけることで予測
* 重要なパラメター: 近傍点の数、データポイント間の距離測度
  * 近傍点の数が1より大きい場合は **投票** でラベル決定
  * 後者はこの本の範疇を超えるとのこと

---

## 2.3 k-最近傍法 k-NN

###  メリット

* モデルの理解のしやすさ
* あまり調整しなくても高い性能が出ることが多い
* ベースラインとして利用可能
* 多くの場合モデル構築が高速

---

## 2.3 k-最近傍法 k-NN

### デメリット

* 訓練セットが多くなると予測が遅くなる
* 多数(数百以上)の特徴量を持つデータセットではうまく機能しない
* ほとんどの特徴量が多くの場合0となるようなデータセットでは性能が悪い

上記の理由から実際はほぼ使われてない...

---

おわり
