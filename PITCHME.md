# Intro to ML with Python 5th

2017/11/30 @mmyoji

---

## 目次

* 4.4 単変量非線形変換
* 4.5 自動特徴量選択
* 4.6 専門家知識の利用
* 4.7 まとめ

---

## 単変量非線形変換

再び, 線形モデルに特に効果があるデータ変換の話

* 前の節では多項式を用いた
* ほとんどのモデルは、個々の特徴量が **ガウス（正規）分布** に従うとき、最もうまく機能する
* log, exp, sin などを用いる

---

## 自動特徴量選択

* なるべく有用な特徴量を取り出す
  * モデルをシンプルにしたい
  * どの特徴量を使えばわからない
  * 予測を高速化したい
  * etc.
* 以下3つの手法を紹介

---

## 単変量統計

* 個々の特徴量とターゲットとの間に統計的に顕著な関係があるかどうかを計算
* クラス分類の場合は **分散分析: ANOVA** として知られる手法
    * 低温調理は関係ない
* 個々の特徴量を個別に見る
  * 他の特徴量との組み合わせで効果があるようなものは無視される
* 計算が高速、モデル構築不要

---

## モデルベース選択

* 教師あり学習モデルを用いて、個々の特徴量の重要性を判断し、重要なものだけ残す
* 特徴量選択に用いる学習モデルと、最終的に使う学習モデルを同じにする必要はない

---

## 反復選択

* 異なる特徴量を用いた、一連のモデルを構築
* 前に出た2つより遥かに計算量が多くなるのでかなり遅い
* a: 全く特徴量を使わないところから、ある基準が満たされるところまで1つずつ特徴量を加える方法
* b: すべての特徴量を使う状態から1つずつ特徴量を削る方法
    * 再帰的特徴量削減 RFE

---

## 専門家知識の利用

* 専門家の知識が活用できる場合は、その知識を特徴量にエンコードし、活用した方がいい
* サンプルコードうごかなかった...

---

## まとめ

（キモいオタク風にしてみた）

* カテゴリ変数の one-hot encoding 使おうな
* 有用な特徴量のみ抽出していこうな
* 専門家の知識、使えるなら使おうな

---

おわり
